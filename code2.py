# -*- coding: utf-8 -*-
"""Untitled34.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yUOcHX-rkvOhAXAL3tbTfY8zfC2PNyaJ
"""

# Mini Project: Large Language Models are Zero-Shot Classifiers
# Dataset: COVID Vaccine Tweets (Kaggle)
# Flowchart used: LLMs Flow (Data Collection -> LLMs -> Classification Results)

# Install necessary libraries
!pip install transformers torch pandas matplotlib tqdm --quiet

import pandas as pd
import re
from tqdm import tqdm
from transformers import pipeline
import matplotlib.pyplot as plt

# ---

# # Step 1: Data Collection (Load Dataset)
# NOTE: You must upload the correct CSV file (e.g., 'vaccination_tweets.csv')
# from the Kaggle dataset linked to your working environment.
FILE_NAME = "covidvaccine.csv" # Changed to the new file name
TEXT_COLUMN = "text"

data = None  # Initialize data to None
try:
    data = pd.read_csv(FILE_NAME)
    print(f"Dataset '{FILE_NAME}' loaded successfully!")
    print(f"Total records: {len(data)}")
    print("\nFirst 5 rows of the dataset:")
    print(data.head())
except FileNotFoundError:
    print(f"Error: '{FILE_NAME}' not found. Please ensure the file is in the correct directory.")

# ---

# Only proceed if the data was loaded successfully
if data is not None:
    # # Step 2: Minimal Preprocessing
    # LLMs are robust, so we only perform essential cleaning (like removing URLs).
    def clean_tweet_llm(text):
        """
        Cleans the tweet text by only removing URLs.
        """
        # Remove URLs (http/https and www)
        text = re.sub(r"http\S+|www\S+", '', str(text))
        # Optionally remove mentions and hashtags if desired, but often kept for context
        text = re.sub(r'[@#]\w+', '', text)
        return text.strip()

    # Apply cleaning function to the original text column
    data['clean_text'] = data[TEXT_COLUMN].apply(clean_tweet_llm)

    # Drop rows where 'clean_text' is missing or becomes empty after cleaning
    data = data.dropna(subset=['clean_text'])

    # Take a small sample for demonstration, as running the model on the full dataset is slow
    SAMPLE_SIZE = 500
    sample_data = data.head(SAMPLE_SIZE).copy() # Use .copy() to avoid SettingWithCopyWarning
    print(f"\nProcessing a sample of {len(sample_data)} tweets...")

    # ---

    # # Step 3: LLMs (Zero-Shot Classification)
    # This step uses the BART-large model to classify the text without training.
    classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    candidate_labels = ["positive", "negative", "neutral"]

    predicted_labels = []
    # Use tqdm for a progress bar during the slow classification step
    for text in tqdm(sample_data['clean_text'], desc='Classifying'):
        # Classifier returns scores for all candidate labels
        result = classifier(text, candidate_labels, multi_label=False)
        # Append the label with the highest score (which is the first one in the list)
        predicted_labels.append(result['labels'][0])

    # Add the predicted sentiments back to the sample_data DataFrame
    sample_data['predicted_sentiment'] = predicted_labels

    # ---

    # # Step 4: Classification Results (Visualization & Display)

    # Visualization
    sentiment_counts = sample_data['predicted_sentiment'].value_counts()

    plt.figure(figsize=(7,5))
    plt.bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'red', 'gray'])
    plt.title(f"Sentiment Distribution on COVID Vaccine Tweets Sample (N={len(sample_data)})")
    plt.xlabel("Predicted Sentiment")
    plt.ylabel("Count")
    plt.show()

    # Display Results
    print("\nFirst 10 Classified Samples:")
    print(sample_data[[TEXT_COLUMN, 'clean_text', 'predicted_sentiment']].head(10))

from google.colab import files
uploaded = files.upload()

# Mini Project: Large Language Models are Zero-Shot Classifiers
# Flow: Data Collection → LLMs → Classification Results
# Dataset: COVID-19 Tweets (Kaggle)

!pip install transformers torch pandas matplotlib tqdm scikit-learn --quiet

import pandas as pd, re, matplotlib.pyplot as plt
from tqdm import tqdm
from transformers import pipeline
from sklearn.metrics import classification_report, accuracy_score

# Step 1: Load Dataset
try:
    df = pd.read_csv("covidvaccine.csv")
    print(f"Dataset loaded successfully! Total records: {len(df)}")
except FileNotFoundError:
    raise SystemExit("Error: 'covidvaccine.csv' not found.")

# Step 2: Clean Text (Light preprocessing for better LLM accuracy)
df['clean_text'] = df['text'].astype(str).apply(lambda x: re.sub(r"http\S+|www\S+|@\w+|#\w+", '', x).strip())
df = df[df['clean_text'].str.len() > 0].head(100)

# Step 3: Zero-Shot Classification using LLM (BART)
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
labels = ["positive", "negative", "neutral"]

def classify(text):
    r = classifier(text, labels)
    return r['labels'][0] if r['scores'][0] > 0.5 else "neutral"

tqdm.pandas(desc="Classifying")
df['predicted_sentiment'] = df['clean_text'].progress_apply(classify)

# Step 4: Results Visualization
counts = df['predicted_sentiment'].value_counts()
plt.bar(counts.index, counts.values, color='skyblue')
plt.title("Sentiment Distribution (Zero-Shot Classification)")
plt.xlabel("Sentiment"); plt.ylabel("Count")
plt.show()

print("\nFirst 10 Classified Samples:")
print(df[['clean_text', 'predicted_sentiment']].head(10))

# Step 5: Accuracy & Classification Report (if ground truth exists)
if 'label' in df.columns:
    y_true = df['label'].astype(str).str.lower()
    y_pred = df['predicted_sentiment'].astype(str).str.lower()
    print("\nModel Evaluation:")
    print("Accuracy:", round(accuracy_score(y_true, y_pred) * 100, 2), "%")
    print("\nClassification Report:\n", classification_report(y_true, y_pred, digits=3))
else:
    print("\n⚠️ No ground truth labels found — accuracy report skipped.")